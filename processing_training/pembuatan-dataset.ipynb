{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import csv\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow_docs.vis import embed\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import shutil\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Import matplotlib libraries\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Some modules to display an animation using imageio.\n",
    "import imageio\n",
    "from IPython.display import HTML, display\n",
    "from collections import deque\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose Estimation Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMoveNetDownloader:\n",
    "    \"\"\"Simple MoveNet downloader - download only, no loading\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir=\"movenet_models\"):\n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    def download_hub_model(self, model_name=\"movenet_lightning\"):\n",
    "        \"\"\"Download MoveNet from TensorFlow Hub with local caching\"\"\"\n",
    "        \n",
    "        model_urls = {\n",
    "            \"movenet_thunder\": \"https://tfhub.dev/google/movenet/singlepose/thunder/4\",\n",
    "            \"movenet_lightning\": \"https://tfhub.dev/google/movenet/singlepose/lightning/4\"\n",
    "        }\n",
    "        \n",
    "        if model_name not in model_urls:\n",
    "            print(f\"âŒ Unsupported model: {model_name}\")\n",
    "            return False\n",
    "        \n",
    "        model_path = self.cache_dir / model_name\n",
    "        \n",
    "        # Check if already exists\n",
    "        if model_path.exists():\n",
    "            print(f\"âœ… Model {model_name} already cached at {model_path}\")\n",
    "            return True\n",
    "        \n",
    "        print(f\"ðŸ“¥ Downloading {model_name} from TensorFlow Hub...\")\n",
    "        print(\"â³ This may take a few minutes...\")\n",
    "        \n",
    "        try:\n",
    "            # Set up temporary cache\n",
    "            temp_cache = str(self.cache_dir / \"temp_hub_cache\")\n",
    "            old_cache = os.environ.get('TFHUB_CACHE_DIR', '')\n",
    "            os.environ['TFHUB_CACHE_DIR'] = temp_cache\n",
    "            \n",
    "            # Download the model\n",
    "            print(\"ðŸ”„ Loading model (this triggers the download)...\")\n",
    "            module = hub.load(model_urls[model_name])\n",
    "            print(\"âœ… Model downloaded successfully!\")\n",
    "            \n",
    "            # Move from temp cache to permanent location\n",
    "            if os.path.exists(temp_cache):\n",
    "                for item in os.listdir(temp_cache):\n",
    "                    item_path = os.path.join(temp_cache, item)\n",
    "                    if os.path.isdir(item_path):\n",
    "                        if model_path.exists():\n",
    "                            shutil.rmtree(model_path)\n",
    "                        shutil.move(item_path, str(model_path))\n",
    "                        print(f\"âœ… Model cached at {model_path}\")\n",
    "                        break\n",
    "                \n",
    "                # Cleanup temp cache\n",
    "                shutil.rmtree(temp_cache, ignore_errors=True)\n",
    "            \n",
    "            # Restore original cache setting\n",
    "            if old_cache:\n",
    "                os.environ['TFHUB_CACHE_DIR'] = old_cache\n",
    "            elif 'TFHUB_CACHE_DIR' in os.environ:\n",
    "                del os.environ['TFHUB_CACHE_DIR']\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Download failed: {e}\")\n",
    "            print(\"ðŸ’¡ This might be due to network issues or TF Hub server problems\")\n",
    "            return False\n",
    "\n",
    "def download_movenet_simple(model_name=\"movenet_lightning\"):\n",
    "    \"\"\"Simple function to download MoveNet - use this in Jupyter\"\"\"\n",
    "    \n",
    "    print(\"ðŸš€ Simple MoveNet Downloader\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    downloader = SimpleMoveNetDownloader()\n",
    "    \n",
    "    if downloader.download_hub_model(model_name):\n",
    "        print(f\"\\nðŸŽ‰ Success! {model_name} is ready to use\")\n",
    "        print(f\"ðŸ“ Cached in: {downloader.cache_dir.absolute()}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"\\nâŒ Failed to download {model_name}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = download_movenet_simple('movenet_lightning')\n",
    "\n",
    "# Step 2: Load the model for use\n",
    "if success:\n",
    "    movenet, input_size = load_movenet_from_cache('movenet_lightning')\n",
    "    \n",
    "    if movenet is not None:\n",
    "        print(f\"ðŸŽ‰ MoveNet ready! Input size: {input_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_movenet_fast(model_name=\"movenet_lighning\", cache_dir=\"movenet_models\"):\n",
    "    \"\"\"\n",
    "    Fast MoveNet loader - loads from your cached model\n",
    "    \"\"\"\n",
    "    cache_path = Path(cache_dir)\n",
    "    model_path = cache_path / model_name\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        raise FileNotFoundError(f\"Model not found at {model_path}\")\n",
    "    \n",
    "    # Load the cached SavedModel\n",
    "    module = tf.saved_model.load(str(model_path))\n",
    "    \n",
    "    def movenet_inference(input_image):\n",
    "        \"\"\"MoveNet inference function - same interface as before\"\"\"\n",
    "        model = module.signatures['serving_default']\n",
    "        input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "        outputs = model(input_image)\n",
    "        keypoints_with_scores = outputs['output_0'].numpy()\n",
    "        return keypoints_with_scores\n",
    "    \n",
    "    input_size = 256 if \"thunder\" in model_name else 192\n",
    "    print(f\"âœ… Loaded {model_name} from cache (input size: {input_size})\")\n",
    "    return movenet_inference, input_size\n",
    "\n",
    "# Step 2: Test the cached model loading\n",
    "movenet, input_size = load_movenet_fast(\"movenet_lightning\", \"movenet_models\")\n",
    "print(f\"ðŸŽ‰ Model loaded in ~2 seconds instead of 60+ seconds!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYPOINT_DICT = {\n",
    "    'nose': 0, 'left_eye': 1, 'right_eye': 2, 'left_ear': 3,\n",
    "    'right_ear': 4, 'left_shoulder': 5,\n",
    "    'right_shoulder': 6, 'left_elbow': 7, 'right_elbow': 8, 'left_wrist': 9,\n",
    "    'right_wrist': 10, 'left_hip': 11, 'right_hip': 12, 'left_knee': 13,\n",
    "    'right_knee': 14, 'left_ankle': 15, 'right_ankle': 16\n",
    "}\n",
    "\n",
    "KEYPOINT_EDGE_INDS_TO_COLOR = {\n",
    "    (5, 3): 'r', (6, 4): 'r', (5, 7): 'b', (7, 9): 'b', (6, 8): 'b', (8, 10): 'b',\n",
    "    (5, 6): 'b', (5, 11): 'orange', (6, 12): 'orange', (7, 5): 'g', (7, 9): 'g',\n",
    "    (8, 6): 'g', (8, 10): 'g', (11, 13): 'purple', (13, 15): 'purple', (12, 14): 'purple', (14, 16): 'purple'\n",
    "}\n",
    "\n",
    "def _keypoints_and_edges_for_display(keypoints_with_scores, height, width, keypoint_threshold=0.3):\n",
    "    keypoints_all = []\n",
    "    keypoint_edges_all = []\n",
    "    edge_colors = []\n",
    "    num_instances, _, _, _ = keypoints_with_scores.shape\n",
    "\n",
    "    for idx in range(num_instances):\n",
    "        kpts_x = keypoints_with_scores[0, idx, :, 1]\n",
    "        kpts_y = keypoints_with_scores[0, idx, :, 0]\n",
    "        kpts_scores = keypoints_with_scores[0, idx, :, 2]\n",
    "        kpts_absolute_xy = np.stack([width * np.array(kpts_x), height * np.array(kpts_y)], axis=-1)\n",
    "        kpts_above_thresh_absolute = kpts_absolute_xy[kpts_scores > keypoint_threshold, :]\n",
    "        keypoints_all.append(kpts_above_thresh_absolute)\n",
    "\n",
    "        for edge_pair, color in KEYPOINT_EDGE_INDS_TO_COLOR.items():\n",
    "            if kpts_scores[edge_pair[0]] > keypoint_threshold and kpts_scores[edge_pair[1]] > keypoint_threshold:\n",
    "                x_start, y_start = kpts_absolute_xy[edge_pair[0]]\n",
    "                x_end, y_end = kpts_absolute_xy[edge_pair[1]]\n",
    "                line_seg = np.array([[x_start, y_start], [x_end, y_end]])\n",
    "                keypoint_edges_all.append(line_seg)\n",
    "                edge_colors.append(color)\n",
    "\n",
    "    keypoints_xy = np.concatenate(keypoints_all, axis=0) if keypoints_all else np.zeros((0, 2))\n",
    "    edges_xy = np.stack(keypoint_edges_all, axis=0) if keypoint_edges_all else np.zeros((0, 2, 2))\n",
    "\n",
    "    return keypoints_xy, edges_xy, edge_colors\n",
    "\n",
    "# Function to draw keypoints and edges on image with confidence\n",
    "def draw_prediction_on_image(image, keypoints_with_scores, original_image=None, flip_applied=False, crop_region=None, close_figure=False, output_image_height=None):\n",
    "    \"\"\"Draws the keypoint predictions on image.\"\"\"\n",
    "    # Use original image if flip was applied (since keypoints are already flipped)\n",
    "    vis_image = original_image if flip_applied else image\n",
    "    \n",
    "    if flip_applied:\n",
    "        # Flip the keypoints back to match the flipped image\n",
    "        width = vis_image.shape[1]\n",
    "        keypoints_with_scores[0, 0, :, 1] = 1 - keypoints_with_scores[0, 0, :, 1]\n",
    "\n",
    "    height, width, _ = vis_image.shape\n",
    "    aspect_ratio = float(width) / height\n",
    "    fig, ax = plt.subplots(figsize=(12 * aspect_ratio, 12))\n",
    "    fig.tight_layout(pad=0)\n",
    "    ax.margins(0)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    plt.axis('off')\n",
    "\n",
    "    im = ax.imshow(vis_image)\n",
    "    line_segments = LineCollection([], linewidths=(4), linestyle='solid')\n",
    "    ax.add_collection(line_segments)\n",
    "    scat = ax.scatter([], [], s=60, color='#FF1493', zorder=3)\n",
    "\n",
    "    (keypoint_locs, keypoint_edges, edge_colors) = _keypoints_and_edges_for_display(keypoints_with_scores, height, width)\n",
    "\n",
    "    line_segments.set_segments(keypoint_edges)\n",
    "    line_segments.set_color(edge_colors)\n",
    "\n",
    "    for i, (keypoint, score) in enumerate(zip(keypoint_locs, keypoints_with_scores[0, 0, :, 2])):\n",
    "        x, y = keypoint\n",
    "        if score > 0.11:  # Only show keypoints with high enough confidence\n",
    "            ax.text(x, y, f'{score:.2f}', fontsize=10, color='white', ha='center', va='center', zorder=4)\n",
    "\n",
    "    if keypoint_edges.shape[0]:\n",
    "        line_segments.set_segments(keypoint_edges)\n",
    "        line_segments.set_color(edge_colors)\n",
    "    if keypoint_locs.shape[0]:\n",
    "        scat.set_offsets(keypoint_locs)\n",
    "\n",
    "    if crop_region is not None:\n",
    "        xmin = max(crop_region['x_min'] * width, 0.0)\n",
    "        ymin = max(crop_region['y_min'] * height, 0.0)\n",
    "        rec_width = min(crop_region['x_max'], 0.99) * width - xmin\n",
    "        rec_height = min(crop_region['y_max'], 0.99) * height - ymin\n",
    "        rect = patches.Rectangle(\n",
    "            (xmin, ymin), rec_width, rec_height,\n",
    "            linewidth=1, edgecolor='b', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    image_from_plot = image_from_plot.reshape(\n",
    "        fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    plt.close(fig)\n",
    "    if output_image_height is not None:\n",
    "        output_image_width = int(output_image_height / height * width)\n",
    "        image_from_plot = cv2.resize(image_from_plot, dsize=(output_image_width, output_image_height),\n",
    "                                     interpolation=cv2.INTER_CUBIC)\n",
    "    return image_from_plot\n",
    "\n",
    "# Cropping Algorithm\n",
    "\n",
    "MIN_CROP_KEYPOINT_SCORE = 0.2\n",
    "\n",
    "def init_crop_region(image_height, image_width):\n",
    "    \"\"\"Defines the default crop region.\"\"\"\n",
    "    if image_width > image_height:\n",
    "        box_height = image_width / image_height\n",
    "        box_width = 1.0\n",
    "        y_min = (image_height / 2 - image_width / 2) / image_height\n",
    "        x_min = 0.0\n",
    "    else:\n",
    "        box_height = 1.0\n",
    "        box_width = image_height / image_width\n",
    "        y_min = 0.0\n",
    "        x_min = (image_width / 2 - image_height / 2) / image_width\n",
    "\n",
    "    return {\n",
    "        'y_min': y_min,\n",
    "        'x_min': x_min,\n",
    "        'y_max': y_min + box_height,\n",
    "        'x_max': x_min + box_width,\n",
    "        'height': box_height,\n",
    "        'width': box_width\n",
    "    }\n",
    "\n",
    "def torso_visible(keypoints):\n",
    "    \"\"\"Checks whether there are enough torso keypoints.\"\"\"\n",
    "    return ((keypoints[0, 0, KEYPOINT_DICT['left_hip'], 2] > MIN_CROP_KEYPOINT_SCORE or\n",
    "             keypoints[0, 0, KEYPOINT_DICT['right_hip'], 2] > MIN_CROP_KEYPOINT_SCORE) and\n",
    "            (keypoints[0, 0, KEYPOINT_DICT['left_shoulder'], 2] > MIN_CROP_KEYPOINT_SCORE or\n",
    "             keypoints[0, 0, KEYPOINT_DICT['right_shoulder'], 2] > MIN_CROP_KEYPOINT_SCORE))\n",
    "\n",
    "def determine_torso_and_body_range(keypoints, target_keypoints, center_y, center_x):\n",
    "    \"\"\"Calculates the maximum distance from each keypoint to the center location.\"\"\"\n",
    "    torso_joints = ['left_shoulder', 'right_shoulder', 'left_hip', 'right_hip']\n",
    "    max_torso_yrange = 0.0\n",
    "    max_torso_xrange = 0.0\n",
    "    for joint in torso_joints:\n",
    "        dist_y = abs(center_y - target_keypoints[joint][0])\n",
    "        dist_x = abs(center_x - target_keypoints[joint][1])\n",
    "        if dist_y > max_torso_yrange:\n",
    "            max_torso_yrange = dist_y\n",
    "        if dist_x > max_torso_xrange:\n",
    "            max_torso_xrange = dist_x\n",
    "\n",
    "    max_body_yrange = 0.0\n",
    "    max_body_xrange = 0.0\n",
    "    for joint in KEYPOINT_DICT.keys():\n",
    "        if keypoints[0, 0, KEYPOINT_DICT[joint], 2] < MIN_CROP_KEYPOINT_SCORE:\n",
    "            continue\n",
    "        dist_y = abs(center_y - target_keypoints[joint][0])\n",
    "        dist_x = abs(center_x - target_keypoints[joint][1])\n",
    "        if dist_y > max_body_yrange:\n",
    "            max_body_yrange = dist_y\n",
    "        if dist_x > max_body_xrange:\n",
    "            max_body_xrange = dist_x\n",
    "\n",
    "    return [max_torso_yrange, max_torso_xrange, max_body_yrange, max_body_xrange]\n",
    "\n",
    "def determine_crop_region(keypoints, image_height, image_width):\n",
    "    \"\"\"Determines the region to crop the image for the model.\"\"\"\n",
    "    target_keypoints = {}\n",
    "    for joint in KEYPOINT_DICT.keys():\n",
    "        target_keypoints[joint] = [\n",
    "            keypoints[0, 0, KEYPOINT_DICT[joint], 0] * image_height,\n",
    "            keypoints[0, 0, KEYPOINT_DICT[joint], 1] * image_width\n",
    "        ]\n",
    "\n",
    "    if torso_visible(keypoints):\n",
    "        center_y = (target_keypoints['left_hip'][0] + target_keypoints['right_hip'][0]) / 2\n",
    "        center_x = (target_keypoints['left_hip'][1] + target_keypoints['right_hip'][1]) / 2\n",
    "\n",
    "        (max_torso_yrange, max_torso_xrange, max_body_yrange, max_body_xrange) = determine_torso_and_body_range(\n",
    "            keypoints, target_keypoints, center_y, center_x)\n",
    "\n",
    "        crop_length_half = np.amax([max_torso_xrange * 1.9, max_torso_yrange * 1.9,\n",
    "                                    max_body_yrange * 1.2, max_body_xrange * 1.2])\n",
    "\n",
    "        tmp = np.array([center_x, image_width - center_x, center_y, image_height - center_y])\n",
    "        crop_length_half = np.amin([crop_length_half, np.amax(tmp)])\n",
    "\n",
    "        crop_corner = [center_y - crop_length_half, center_x - crop_length_half]\n",
    "\n",
    "        if crop_length_half > max(image_width, image_height) / 2:\n",
    "            return init_crop_region(image_height, image_width)\n",
    "        else:\n",
    "            crop_length = crop_length_half * 2\n",
    "            return {\n",
    "                'y_min': crop_corner[0] / image_height,\n",
    "                'x_min': crop_corner[1] / image_width,\n",
    "                'y_max': (crop_corner[0] + crop_length) / image_height,\n",
    "                'x_max': (crop_corner[1] + crop_length) / image_width,\n",
    "                'height': (crop_corner[0] + crop_length) / image_height - crop_corner[0] / image_height,\n",
    "                'width': (crop_corner[1] + crop_length) / image_width - crop_corner[1] / image_width\n",
    "            }\n",
    "    else:\n",
    "        return init_crop_region(image_height, image_width)\n",
    "\n",
    "def crop_and_resize(image, crop_region, crop_size):\n",
    "    \"\"\"Crops and resizes the image to prepare for the model input.\"\"\"\n",
    "    boxes=[[crop_region['y_min'], crop_region['x_min'],\n",
    "            crop_region['y_max'], crop_region['x_max']]]\n",
    "    output_image = tf.image.crop_and_resize(\n",
    "        image, box_indices=[0], boxes=boxes, crop_size=crop_size)\n",
    "    return output_image\n",
    "\n",
    "def should_flip_image(keypoints_with_scores):\n",
    "    \"\"\"Determines if the image should be flipped based on keypoint positions.\"\"\"\n",
    "    # Get relevant keypoints with confidence checks\n",
    "    left_shoulder = keypoints_with_scores[0, 0, KEYPOINT_DICT['left_shoulder']]\n",
    "    right_shoulder = keypoints_with_scores[0, 0, KEYPOINT_DICT['right_shoulder']]\n",
    "    left_wrist = keypoints_with_scores[0, 0, KEYPOINT_DICT['left_wrist']]\n",
    "    left_knee = keypoints_with_scores[0, 0, KEYPOINT_DICT['left_knee']]\n",
    "\n",
    "    score = 0\n",
    "    valid_keypoints = 0\n",
    "    \n",
    "    # Shoulder comparison\n",
    "    if left_shoulder[2] > KEYPOINT_THRESHOLD and right_shoulder[2] > KEYPOINT_THRESHOLD:\n",
    "        if left_shoulder[1] > right_shoulder[1]:\n",
    "            score += 1  # Facing left\n",
    "        else:\n",
    "            score -= 1  # Facing right\n",
    "        valid_keypoints += 1\n",
    "    \n",
    "    # Wrist position\n",
    "    if left_wrist[2] > KEYPOINT_THRESHOLD and left_shoulder[2] > KEYPOINT_THRESHOLD:\n",
    "        if left_wrist[1] < left_shoulder[1]:\n",
    "            score += 1  # Facing left\n",
    "        else:\n",
    "            score -= 1  # Facing right\n",
    "        valid_keypoints += 1\n",
    "    \n",
    "    # Knee position\n",
    "    if left_knee[2] > KEYPOINT_THRESHOLD and left_shoulder[2] > KEYPOINT_THRESHOLD:\n",
    "        if left_knee[1] < left_shoulder[1]:\n",
    "            score += 1  # Facing left\n",
    "        else:\n",
    "            score -= 1  # Facing right\n",
    "        valid_keypoints += 1\n",
    "    \n",
    "    return score > 0 if valid_keypoints >= 2 else False\n",
    "\n",
    "def flip_image_and_keypoints(image, keypoints_with_scores):\n",
    "    \"\"\"Flips the image and keypoints horizontally.\"\"\"\n",
    "    # Flip keypoints\n",
    "    keypoints_with_scores[0, 0, :, 1] = 1 - keypoints_with_scores[0, 0, :, 1]\n",
    "    \n",
    "    # Flip image\n",
    "    flipped_image = cv2.flip(image, 1)\n",
    "    \n",
    "    return keypoints_with_scores, flipped_image\n",
    "\n",
    "\n",
    "# Confidence threshold for keypoints\n",
    "KEYPOINT_THRESHOLD = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Angle Calc Save Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(movenet, image, crop_region, crop_size):\n",
    "    \"\"\"Runs model inference on the cropped region with proper flip handling.\"\"\"\n",
    "    image_height, image_width, _ = image.shape\n",
    "    \n",
    "    # First pass to determine orientation\n",
    "    input_image = crop_and_resize(tf.expand_dims(image, axis=0), crop_region, crop_size=crop_size)\n",
    "    keypoints_with_scores = movenet(input_image)\n",
    "    flip_required = should_flip_image(keypoints_with_scores)\n",
    "    \n",
    "    # Second pass if flipping is needed\n",
    "    if flip_required:\n",
    "        flipped_image = cv2.flip(image, 1)\n",
    "        input_image = crop_and_resize(tf.expand_dims(flipped_image, axis=0), crop_region, crop_size=crop_size)\n",
    "        keypoints_with_scores = movenet(input_image)\n",
    "        original_image = image.copy()\n",
    "        image = flipped_image\n",
    "    else:\n",
    "        original_image = image.copy()\n",
    "    \n",
    "    # Adjust keypoints for crop region\n",
    "    for idx in range(17):\n",
    "        keypoints_with_scores[0, 0, idx, 0] = (\n",
    "            crop_region['y_min'] * image_height +\n",
    "            crop_region['height'] * image_height *\n",
    "            keypoints_with_scores[0, 0, idx, 0]) / image_height\n",
    "        keypoints_with_scores[0, 0, idx, 1] = (\n",
    "            crop_region['x_min'] * image_width +\n",
    "            crop_region['width'] * image_width *\n",
    "            keypoints_with_scores[0, 0, idx, 1]) / image_width\n",
    "\n",
    "    return keypoints_with_scores, image, original_image, flip_required\n",
    "  \n",
    "\n",
    "\n",
    "def save_visualized_frame(frame, output_folder, frame_idx, flip_applied):\n",
    "    \"\"\"Save the visualized frame to the output folder with flip check.\"\"\"\n",
    "    # If the flip was applied, flip the frame back before saving\n",
    "    if flip_applied:\n",
    "        frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    output_path = os.path.join(output_folder, f\"frame_{frame_idx:04d}.png\")\n",
    "    cv2.imwrite(output_path, frame)\n",
    "    print(f\"Saved frame {frame_idx} to {output_path}\")\n",
    "\n",
    "# Helper function to calculate joint angles using cosine law\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    cosine_angle = np.clip(cosine_angle, -1.0, 1.0)\n",
    "    angle = np.degrees(np.arccos(cosine_angle))\n",
    "    return angle\n",
    "\n",
    "def get_video_rotation(video_path):\n",
    "    \"\"\"Detect video rotation using OpenCV\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    rotation = 0\n",
    "    try:\n",
    "        # Trying to detect rotation from metadata\n",
    "        if cap.get(cv2.CAP_PROP_ORIENTATION_META) == 90:\n",
    "            rotation = 90\n",
    "        elif cap.get(cv2.CAP_PROP_ORIENTATION_META) == 180:\n",
    "            rotation = 180\n",
    "        elif cap.get(cv2.CAP_PROP_ORIENTATION_META) == 270:\n",
    "            rotation = 270\n",
    "    except Exception as e:\n",
    "        print(f\"Error while reading video metadata: {e}\")\n",
    "    cap.release()\n",
    "    return rotation\n",
    "\n",
    "def apply_rotation(frame, angle):\n",
    "        if angle == 90:\n",
    "            return cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        elif angle == 180:\n",
    "            return cv2.rotate(frame, cv2.ROTATE_180)\n",
    "        elif angle == 270:\n",
    "            return cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reba Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrunkREBA:\n",
    "    \"\"\"\n",
    "    Standard REBA implementation for trunk scoring.\n",
    "    \n",
    "    Angle convention: \n",
    "    - Positive angle = forward flexion (leaning forward)\n",
    "    - Negative angle = extension (leaning backward)\n",
    "    \n",
    "    Standard REBA trunk scoring:\n",
    "    - 0-5Â° flexion: Score 1\n",
    "    - 5-20Â° flexion: Score 2\n",
    "    - 20-60Â° flexion: Score 3\n",
    "    - >60Â° flexion: Score 4\n",
    "    \"\"\"\n",
    "    def __init__(self, trunk_degrees):\n",
    "        self.trunk_degrees = trunk_degrees\n",
    "\n",
    "    def trunk_reba_score(self):\n",
    "        waist_angle = self.trunk_degrees[0]  # Waist angle from get_joint_angles_and_labels\n",
    "        \n",
    "        # Base score starts at 0\n",
    "        trunk_reba_score = 0\n",
    "        \n",
    "        # Standard REBA thresholds\n",
    "        if waist_angle >= 0:  # Positive angle = forward flexion\n",
    "            if 0 <= waist_angle <= 5:  # 0-5 degrees flexion\n",
    "                trunk_reba_score = 1\n",
    "            elif 5 < waist_angle <= 20:  # 5-20 degrees flexion\n",
    "                trunk_reba_score = 2\n",
    "            elif 20 < waist_angle <= 60:  # 20-60 degrees flexion\n",
    "                trunk_reba_score = 3\n",
    "            elif 60 < waist_angle:  \n",
    "                trunk_reba_score = 4\n",
    "            \n",
    "        else:  # Negative angle = extension/backward lean\n",
    "            abs_angle = abs(waist_angle)\n",
    "            if 0 < abs_angle <= 5:  # 0-5 degrees extension\n",
    "                trunk_reba_score = 1\n",
    "            elif 5 < abs_angle:  \n",
    "                trunk_reba_score = 2\n",
    "        \n",
    "        return [trunk_reba_score, 0, 0]\n",
    "\n",
    "class NeckREBA:\n",
    "    \"\"\"  \n",
    "    Standard REBA neck scoring:\n",
    "    - 0-20Â° flexion: Score 1\n",
    "    - >20Â° flexion: Score 2\n",
    "    - Any extension: Score 2\n",
    "    \"\"\"\n",
    "    def __init__(self, neck_degrees):\n",
    "        self.neck_degrees = neck_degrees\n",
    "\n",
    "    def neck_reba_score(self):\n",
    "        neck_angle = self.neck_degrees[0]  # Raw neck angle from get_joint_angles_and_labels\n",
    "        \n",
    "        # Base score starts at 0\n",
    "        neck_reba_score = 0\n",
    "        \n",
    "        # Standard REBA thresholds for neck\n",
    "        if 0 <= neck_angle < 20:  # 0-20 degrees flexion\n",
    "            neck_reba_score = 1\n",
    "        elif neck_angle >= 20:  # >20 degrees flexion\n",
    "            neck_reba_score = 2\n",
    "        elif neck_angle < 0:  # Extension\n",
    "            neck_reba_score = 2\n",
    "                \n",
    "        return [neck_reba_score, 0, 0]\n",
    "\n",
    "\n",
    "class UpperArmREBA:\n",
    "    \"\"\"\n",
    "    For calculating REBA score based on upper arm angles\n",
    "    - Using standard REBA thresholds without buffer\n",
    "    - Only using flexion for scoring, ignoring other factors\n",
    "    \"\"\"\n",
    "    def __init__(self, arm_degrees):\n",
    "        self.arm_degrees = arm_degrees  # [left_angle, right_angle]\n",
    "\n",
    "    def upper_arm_score(self):\n",
    "        left_angle = self.arm_degrees[0]\n",
    "        right_angle = self.arm_degrees[1]\n",
    "        \n",
    "        # Take the worst case between left and right arm\n",
    "        max_angle = max(abs(left_angle), abs(right_angle))\n",
    "        \n",
    "        # Base score\n",
    "        upper_arm_reba_score = 0\n",
    "        \n",
    "        # Standard REBA thresholds without buffer\n",
    "        if -20 <= max_angle < 20:  # -20 to 20 degrees\n",
    "            upper_arm_reba_score = 1\n",
    "        elif 20 <= max_angle < 45:  # 20 to 45 degrees\n",
    "            upper_arm_reba_score = 2\n",
    "        elif max_angle < -20 or (45 <= max_angle < 90):  # <-20 or 45 to 90 degrees\n",
    "            upper_arm_reba_score = 3\n",
    "        elif 90 <= max_angle:  # >90 degrees\n",
    "            upper_arm_reba_score = 4\n",
    "            \n",
    "        return [upper_arm_reba_score]  \n",
    "\n",
    "\n",
    "class LAREBA:\n",
    "    \"\"\"\n",
    "    For calculating REBA score based on lower arm angles\n",
    "    Using standard REBA thresholds with minor adjustments\n",
    "    \n",
    "    Standard REBA lower arm scoring:\n",
    "    - 60-100Â°: Score 1 (neutral)\n",
    "    - <60Â° or >100Â°: Score 2\n",
    "    \n",
    "    Input: List of measured reflex angles [left_reflex, right_reflex]\n",
    "    \"\"\"\n",
    "    def __init__(self, reflex_angles):\n",
    "        # Convert reflex angles to elbow bend angles\n",
    "        self.elbow_bend_angles = [180 - angle for angle in reflex_angles]\n",
    "\n",
    "    def lower_arm_score(self):\n",
    "        left_bend = self.elbow_bend_angles[0]\n",
    "        right_bend = self.elbow_bend_angles[1]\n",
    "        \n",
    "        left_score = self._score_single_arm(left_bend)\n",
    "        right_score = self._score_single_arm(right_bend)\n",
    "        \n",
    "        return [max(left_score, right_score)]  # Return worst score\n",
    "    \n",
    "    def _score_single_arm(self, bend_angle):\n",
    "        \"\"\"Score based on elbow bend angle\"\"\"\n",
    "        if 60 <= bend_angle <= 100:\n",
    "            return 1  # Neutral\n",
    "        return 2  # Non-neutral\n",
    "\n",
    "\n",
    "class LegREBA:\n",
    "    \"\"\"\n",
    "    For calculating REBA score based on leg angles\n",
    "    Updated per expert feedback: legs don't matter for sitting assessment\n",
    "    Always returns score of 1 (neutral) regardless of leg angles\n",
    "    \"\"\"\n",
    "    def __init__(self, leg_degrees):\n",
    "        self.leg_degrees = leg_degrees  # [left_angle, right_angle] - kept for future compatibility\n",
    "\n",
    "    def leg_reba_score(self):\n",
    "        \"\"\"\n",
    "        Returns neutral score of 1 for all leg positions\n",
    "        Per ergonomics expert: leg angles don't matter for sitting assessment\n",
    "        \"\"\"\n",
    "        # Always return 1 (neutral) - legs don't matter for sitting\n",
    "        leg_reba_score = 1\n",
    "        return [leg_reba_score]\n",
    "\n",
    "class AngleSmoother:\n",
    "    \"\"\"Helper class to smooth angle measurements\"\"\"\n",
    "    def __init__(self, window_size=3):\n",
    "        from collections import deque\n",
    "        import numpy as np\n",
    "        self.history = deque(maxlen=window_size)\n",
    "        self.np = np\n",
    "        \n",
    "    def smooth(self, angle):\n",
    "        if angle is not None:\n",
    "            self.history.append(angle)\n",
    "            return self.np.mean(self.history)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Pose Inference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get a valid keypoint\n",
    "def get_keypoint_if_valid(validated_keypoints, keypoint_name):\n",
    "    kp = validated_keypoints[keypoint_name]\n",
    "    return (kp['y'], kp['x']) if kp['valid'] else None\n",
    "\n",
    "# Helper function to calculate the angle with fallback\n",
    "def calculate_angle_with_fallback(a_name, b_name, c_name, angle_name, validated_keypoints, imputed_angles, neutral_angles):\n",
    "    a = get_keypoint_if_valid(validated_keypoints, a_name)\n",
    "    b = get_keypoint_if_valid(validated_keypoints, b_name)\n",
    "    c = get_keypoint_if_valid(validated_keypoints, c_name)\n",
    "    \n",
    "    if a is not None and b is not None and c is not None:\n",
    "        try:\n",
    "            angle = calculate_angle(a, b, c)\n",
    "            return angle\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # If we get here, use neutral angle and flag as imputed\n",
    "    imputed_angles[angle_name] = True\n",
    "    return neutral_angles[angle_name]\n",
    "\n",
    "\n",
    "def get_reba_tables():\n",
    "    \"\"\"\n",
    "    Returns the REBA scoring tables (A, B, and C).\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the three REBA tables\n",
    "    \"\"\"\n",
    "    # TABLE A: Neck, Trunk, and Legs scores\n",
    "    # 3D lookup table: table_a[neck][trunk][legs]\n",
    "    table_a = [\n",
    "        # Neck = 1\n",
    "        [\n",
    "            [1, 2, 3, 4],  # Trunk = 1\n",
    "            [2, 3, 4, 5],  # Trunk = 2\n",
    "            [2, 4, 5, 6],  # Trunk = 3\n",
    "            [3, 5, 6, 7],  # Trunk = 4\n",
    "            [4, 6, 7, 8],  # Trunk = 5\n",
    "        ],\n",
    "        # Neck = 2\n",
    "        [\n",
    "            [1, 3, 4, 5],  # Trunk = 1\n",
    "            [2, 4, 5, 6],  # Trunk = 2\n",
    "            [3, 5, 6, 7],  # Trunk = 3\n",
    "            [4, 6, 7, 8],  # Trunk = 4\n",
    "            [5, 7, 8, 9],  # Trunk = 5\n",
    "        ],\n",
    "        # Neck = 3\n",
    "        [\n",
    "            [3, 4, 5, 6],  # Trunk = 1\n",
    "            [3, 5, 6, 7],  # Trunk = 2\n",
    "            [4, 6, 7, 8],  # Trunk = 3\n",
    "            [5, 7, 8, 9],  # Trunk = 4\n",
    "            [6, 8, 9, 10],  # Trunk = 5\n",
    "        ],\n",
    "    ]\n",
    "    \n",
    "    # TABLE B: Upper Arm, Lower Arm, and Wrist scores\n",
    "    # 3D lookup table: table_b[upper_arm][lower_arm][wrist]\n",
    "    table_b = [\n",
    "        # Upper Arm = 1\n",
    "        [\n",
    "            [1, 2, 2],  # Lower Arm = 1\n",
    "            [1, 2, 3],  # Lower Arm = 2\n",
    "        ],\n",
    "        # Upper Arm = 2\n",
    "        [\n",
    "            [1, 2, 3],  # Lower Arm = 1\n",
    "            [2, 3, 4],  # Lower Arm = 2\n",
    "        ],\n",
    "        # Upper Arm = 3\n",
    "        [\n",
    "            [3, 4, 5],  # Lower Arm = 1\n",
    "            [3, 4, 5],  # Lower Arm = 2\n",
    "        ],\n",
    "        # Upper Arm = 4\n",
    "        [\n",
    "            [4, 5, 5],  # Lower Arm = 1\n",
    "            [4, 5, 6],  # Lower Arm = 2\n",
    "        ],\n",
    "        # Upper Arm = 5\n",
    "        [\n",
    "            [6, 7, 8],  # Lower Arm = 1\n",
    "            [6, 7, 8],  # Lower Arm = 2\n",
    "        ],\n",
    "        # Upper Arm = 6\n",
    "        [\n",
    "            [7, 8, 8],  # Lower Arm = 1\n",
    "            [7, 8, 9],  # Lower Arm = 2\n",
    "        ],\n",
    "    ]\n",
    "    \n",
    "    # TABLE C: Score A and Score B combination\n",
    "    # 2D lookup table: table_c[score_a][score_b]\n",
    "    table_c = [\n",
    "        [1, 1, 1, 2, 3, 3, 4, 5, 6, 7, 7, 7],  # Score A = 1\n",
    "        [1, 2, 2, 3, 4, 4, 5, 6, 6, 7, 7, 8],  # Score A = 2\n",
    "        [2, 3, 3, 3, 4, 5, 6, 7, 7, 8, 8, 8],  # Score A = 3\n",
    "        [3, 4, 4, 4, 5, 6, 7, 8, 8, 9, 9, 9],  # Score A = 4\n",
    "        [4, 4, 4, 5, 6, 7, 8, 8, 9, 9, 9, 9],  # Score A = 5\n",
    "        [6, 6, 6, 7, 8, 8, 9, 9, 10, 10, 10, 10],  # Score A = 6\n",
    "        [7, 7, 7, 8, 9, 9, 9, 10, 10, 11, 11, 11],  # Score A = 7\n",
    "        [8, 8, 8, 9, 10, 10, 10, 10, 10, 11, 11, 11],  # Score A = 8\n",
    "        [9, 9, 9, 10, 10, 10, 11, 11, 11, 12, 12, 12],  # Score A = 9\n",
    "        [10, 10, 10, 11, 11, 11, 11, 12, 12, 12, 12, 12],  # Score A = 10\n",
    "        [11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12],  # Score A = 11\n",
    "        [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12],  # Score A = 12\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"table_a\": table_a,\n",
    "        \"table_b\": table_b,\n",
    "        \"table_c\": table_c\n",
    "    }\n",
    "\n",
    "def calculate_final_reba_score(neck_score, trunk_score, leg_score, upper_arm_score, lower_arm_score, \n",
    "                             wrist_score=1, load_score=0, coupling_score=0, activity_score=0,\n",
    "                             is_sitting=True, return_details=False):\n",
    "    \"\"\"\n",
    "    Calculate REBA score using Table A, Table B, and Table C lookups.\n",
    "    \n",
    "    Args:\n",
    "        neck_score: Score for neck posture (1-3)\n",
    "        trunk_score: Score for trunk posture (1-6)\n",
    "        leg_score: Score for leg posture (1-4)\n",
    "        upper_arm_score: Score for upper arm posture (1-6)\n",
    "        lower_arm_score: Score for lower arm posture (1-3)\n",
    "        wrist_score: Score for wrist posture (default=1, neutral)\n",
    "        load_score: Score for load/force (default=0)\n",
    "        coupling_score: Score for coupling/grip (default=0)\n",
    "        activity_score: Score for activity type (default=0)\n",
    "        is_sitting: Boolean for sitting posture (default=True)\n",
    "        return_details: Whether to return intermediate scores (default=False)\n",
    "    \n",
    "    Returns:\n",
    "        If return_details=False: tuple (final_score, risk_level)\n",
    "        If return_details=True: tuple (final_score, risk_level, intermediate_scores)\n",
    "    \"\"\"\n",
    "    # Adjust leg score for sitting posture if needed\n",
    "    if is_sitting:\n",
    "        # Sitting typically has a minimum leg score of 1 \n",
    "        # (since legs are supported when sitting correctly)\n",
    "        leg_score = max(1, leg_score)\n",
    "    \n",
    "    # Get the REBA scoring tables\n",
    "    tables = get_reba_tables()\n",
    "    table_a = tables[\"table_a\"]\n",
    "    table_b = tables[\"table_b\"]\n",
    "    table_c = tables[\"table_c\"]\n",
    "    \n",
    "    # Make sure scores are within valid range for table lookup\n",
    "    neck_idx = min(max(neck_score - 1, 0), 2)  # 0-2 index for scores 1-3\n",
    "    trunk_idx = min(max(trunk_score - 1, 0), 4)  # 0-4 index for scores 1-5\n",
    "    leg_idx = min(max(leg_score - 1, 0), 3)  # 0-3 index for scores 1-4\n",
    "    \n",
    "    # Table A lookup\n",
    "    score_a = table_a[neck_idx][trunk_idx][leg_idx]\n",
    "    \n",
    "    # Add load/force score\n",
    "    score_a += load_score\n",
    "    \n",
    "    # Make sure scores are within valid range for table lookup\n",
    "    upper_arm_idx = min(max(upper_arm_score - 1, 0), 5)  # 0-5 index for scores 1-6\n",
    "    lower_arm_idx = min(max(lower_arm_score - 1, 0), 1)  # 0-1 index for scores 1-2\n",
    "    wrist_idx = min(max(wrist_score - 1, 0), 2)  # 0-2 index for scores 1-3\n",
    "    \n",
    "    # Table B lookup\n",
    "    score_b = table_b[upper_arm_idx][lower_arm_idx][wrist_idx]\n",
    "    \n",
    "    # Add coupling score\n",
    "    score_b += coupling_score\n",
    "    \n",
    "    # Make sure scores are within valid range for table lookup\n",
    "    score_a_idx = min(max(score_a - 1, 0), 11)  # 0-11 index for scores 1-12\n",
    "    score_b_idx = min(max(score_b - 1, 0), 11)  # 0-11 index for scores 1-12\n",
    "    \n",
    "    # Table C lookup\n",
    "    score_c = table_c[score_a_idx][score_b_idx]\n",
    "    \n",
    "    # Add activity score\n",
    "    final_score = score_c + activity_score\n",
    "    \n",
    "    # Determine risk level\n",
    "    if final_score <= 1:\n",
    "        risk_level = \"Negligible\"\n",
    "    elif final_score <= 3:\n",
    "        risk_level = \"Low\"\n",
    "    elif final_score <= 7:\n",
    "        risk_level = \"Medium\"\n",
    "    elif final_score <= 10:\n",
    "        risk_level = \"High\"\n",
    "    else:\n",
    "        risk_level = \"Very High\"\n",
    "    \n",
    "    # Either return just the basic info or include the intermediate scores\n",
    "    if return_details:\n",
    "        # Create intermediate scores dictionary\n",
    "        intermediate_scores = {\n",
    "            \"score_a\": score_a,\n",
    "            \"score_b\": score_b,\n",
    "            \"score_c\": score_c,\n",
    "            \"neck_score\": neck_score,\n",
    "            \"trunk_score\": trunk_score,\n",
    "            \"leg_score\": leg_score,\n",
    "            \"upper_arm_score\": upper_arm_score,\n",
    "            \"lower_arm_score\": lower_arm_score,\n",
    "            \"wrist_score\": wrist_score,\n",
    "            \"load_score\": load_score,\n",
    "            \"coupling_score\": coupling_score,\n",
    "            \"activity_score\": activity_score\n",
    "        }\n",
    "        return final_score, risk_level, intermediate_scores\n",
    "    \n",
    "    \n",
    "    return final_score, risk_level\n",
    "\n",
    "\n",
    "def get_joint_angles_and_labels(keypoints_with_scores, keypoint_threshold=KEYPOINT_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Calculate joint angles and REBA scores from pose keypoints\n",
    "    \n",
    "    Args:\n",
    "        keypoints_with_scores: Output from MoveNet model\n",
    "        keypoint_threshold: Confidence threshold for valid keypoints\n",
    "    \n",
    "    Returns:\n",
    "        dict: Contains all angles, REBA scores, and risk assessment\n",
    "    \"\"\"\n",
    "    keypoints = keypoints_with_scores[0, 0, :, :2]\n",
    "    scores = keypoints_with_scores[0, 0, :, 2]\n",
    "\n",
    "    # Initialize smoothers if they don't exist\n",
    "    if not hasattr(get_joint_angles_and_labels, 'smoothers'):\n",
    "        get_joint_angles_and_labels.smoothers = {\n",
    "            'left_leg': AngleSmoother(),\n",
    "            'right_leg': AngleSmoother(),\n",
    "            'neck': AngleSmoother(),\n",
    "            'trunk': AngleSmoother(),\n",
    "            'upper_arm': AngleSmoother(),\n",
    "            'lower_arm': AngleSmoother(),\n",
    "        }\n",
    "\n",
    "    # Initialize tracking dictionaries\n",
    "    imputed_angles = {\n",
    "        'left_leg': False,\n",
    "        'right_leg': False,\n",
    "        'neck': False,\n",
    "        'waist': False,\n",
    "        'left_upper_arm': False,\n",
    "        'right_upper_arm': False,\n",
    "        'left_lower_arm': False,\n",
    "        'right_lower_arm': False\n",
    "    }\n",
    "\n",
    "    neutral_angles = {\n",
    "        'left_leg': 100,\n",
    "        'right_leg': 100,\n",
    "        'left_upper_arm': 0,\n",
    "        'right_upper_arm': 0,\n",
    "        'left_lower_arm': 90,\n",
    "        'right_lower_arm': 90,\n",
    "        'waist': 110,\n",
    "        'neck': 170\n",
    "    }\n",
    "\n",
    "    # Create validated keypoints dictionary\n",
    "    validated_keypoints = {}\n",
    "    for name, idx in KEYPOINT_DICT.items():\n",
    "        validated_keypoints[name] = {\n",
    "            'x': keypoints[idx][1] if scores[idx] > keypoint_threshold else None,\n",
    "            'y': keypoints[idx][0] if scores[idx] > keypoint_threshold else None,\n",
    "            'valid': scores[idx] > keypoint_threshold\n",
    "        }\n",
    "\n",
    "    # Calculate all angles with fallback\n",
    "    angles = {}\n",
    "    \n",
    "    # Calculate waist angle (with forward/backward detection)\n",
    "    shoulder_left = get_keypoint_if_valid(validated_keypoints, 'left_shoulder')\n",
    "    shoulder_right = get_keypoint_if_valid(validated_keypoints, 'right_shoulder')\n",
    "    hip_left = get_keypoint_if_valid(validated_keypoints, 'left_hip')\n",
    "    hip_right = get_keypoint_if_valid(validated_keypoints, 'right_hip')\n",
    "    \n",
    "    if all([shoulder_left, shoulder_right, hip_left, hip_right]):\n",
    "        # Original angle calculation\n",
    "        shoulder_vec = np.array([shoulder_left[0] - shoulder_right[0],\n",
    "                               shoulder_left[1] - shoulder_right[1]])\n",
    "        hip_vec = np.array([hip_left[0] - hip_right[0],\n",
    "                           hip_left[1] - hip_right[1]])\n",
    "        \n",
    "        dot_product = np.dot(shoulder_vec, hip_vec)\n",
    "        shoulder_mag = np.linalg.norm(shoulder_vec)\n",
    "        hip_mag = np.linalg.norm(hip_vec)\n",
    "        \n",
    "        if shoulder_mag > 0 and hip_mag > 0:\n",
    "            cos_angle = dot_product / (shoulder_mag * hip_mag)\n",
    "            cos_angle = np.clip(cos_angle, -1.0, 1.0)\n",
    "            unsigned_angle = np.degrees(np.arccos(cos_angle))\n",
    "            \n",
    "            # Trunk flexion (forward/backward lean)\n",
    "            shoulder_center_y = (shoulder_left[1] + shoulder_right[1]) / 2\n",
    "            hip_center_y = (hip_left[1] + hip_right[1]) / 2\n",
    "            \n",
    "            # Forward lean (shoulders lower than hips in image coordinates)\n",
    "            if shoulder_center_y > hip_center_y:\n",
    "                angles['waist'] = unsigned_angle  # Positive for forward\n",
    "                angles['waist_direction'] = \"forward\"\n",
    "            else:\n",
    "                angles['waist'] = -unsigned_angle  # Negative for backward\n",
    "                angles['waist_direction'] = \"backward\"\n",
    "            \n",
    "            imputed_angles['waist'] = False\n",
    "        else:\n",
    "            angles['waist'] = neutral_angles['waist']\n",
    "            imputed_angles['waist'] = True\n",
    "    else:\n",
    "        angles['waist'] = neutral_angles['waist']\n",
    "        imputed_angles['waist'] = True\n",
    "\n",
    "    # Calculate neck angle\n",
    "    ear_point = get_keypoint_if_valid(validated_keypoints, 'left_ear')\n",
    "    if ear_point is None:\n",
    "        ear_point = get_keypoint_if_valid(validated_keypoints, 'right_ear')\n",
    "    \n",
    "    if ear_point is not None and shoulder_left is not None and shoulder_right is not None:\n",
    "        # Calculate midpoint between shoulders\n",
    "        mid_shoulder = ((shoulder_left[0] + shoulder_right[0])/2, \n",
    "                       (shoulder_left[1] + shoulder_right[1])/2)\n",
    "        \n",
    "        # Calculate angle between ear and mid-shoulder point (vertical line)\n",
    "        # Create a point directly above mid_shoulder (same x, lower y in image coordinates)\n",
    "        vertical_point = (mid_shoulder[0] - 1, mid_shoulder[1])\n",
    "        \n",
    "        try:\n",
    "            angle = calculate_angle(ear_point, mid_shoulder, vertical_point)\n",
    "            angles['neck'] = angle\n",
    "            imputed_angles['neck'] = False\n",
    "        except:\n",
    "            angles['neck'] = neutral_angles['neck']\n",
    "            imputed_angles['neck'] = True\n",
    "    else:\n",
    "        angles['neck'] = neutral_angles['neck']\n",
    "        imputed_angles['neck'] = True\n",
    "\n",
    "    # Calculate other angles\n",
    "    angle_mapping = {\n",
    "        'left_upper_arm': ('left_hip', 'left_shoulder', 'left_elbow'),\n",
    "        'right_upper_arm': ('right_hip', 'right_shoulder', 'right_elbow'),\n",
    "        'left_lower_arm': ('left_shoulder', 'left_elbow', 'left_wrist'),\n",
    "        'right_lower_arm': ('right_shoulder', 'right_elbow', 'right_wrist'),\n",
    "        'left_leg': ('left_hip', 'left_knee', 'left_ankle'),\n",
    "        'right_leg': ('right_hip', 'right_knee', 'right_ankle')\n",
    "    }\n",
    "\n",
    "    for angle_name, points in angle_mapping.items():\n",
    "        angles[angle_name] = calculate_angle_with_fallback(\n",
    "            points[0], points[1], points[2], angle_name,\n",
    "            validated_keypoints, imputed_angles, neutral_angles)\n",
    "\n",
    "    # Apply smoothing\n",
    "    for angle_name in angles:\n",
    "        if angle_name in get_joint_angles_and_labels.smoothers:\n",
    "            angles[angle_name] = get_joint_angles_and_labels.smoothers[angle_name].smooth(angles[angle_name])\n",
    "\n",
    "    # Check if we have minimum required angles (neck + waist + at least one other)\n",
    "    has_minimum_angles = not imputed_angles['neck'] and not imputed_angles['waist']\n",
    "\n",
    "    if not has_minimum_angles:\n",
    "        missing_angles = []\n",
    "        if imputed_angles['neck']:\n",
    "            missing_angles.append(\"neck\")\n",
    "        if imputed_angles['waist']:\n",
    "            missing_angles.append(\"waist\")\n",
    "        \n",
    "        print(f\"âš  Skipping frame - Missing: {', '.join(missing_angles)}\")\n",
    "        return None, None\n",
    "\n",
    "    # Calculate individual REBA scores\n",
    "    upper_arm_reba = UpperArmREBA([angles['left_upper_arm'], angles['right_upper_arm']]).upper_arm_score()[0]\n",
    "    lower_arm_reba = LAREBA([angles['left_lower_arm'], angles['right_lower_arm']]).lower_arm_score()[0]\n",
    "    neck_reba = NeckREBA([angles['neck'], 0, 0]).neck_reba_score()[0]\n",
    "    trunk_reba = TrunkREBA([angles['waist'], 0, 0]).trunk_reba_score()[0]\n",
    "    leg_reba = LegREBA([angles['left_leg'], angles['right_leg']]).leg_reba_score()[0]\n",
    "\n",
    "    # Calculate final score\n",
    "    final_score, risk_level, intermediate_scores = calculate_final_reba_score(\n",
    "        neck_reba, trunk_reba, leg_reba, upper_arm_reba, lower_arm_reba,\n",
    "        is_sitting=True,  \n",
    "        return_details=True  \n",
    "    )\n",
    "\n",
    "    # Prepare complete output\n",
    "    result = {\n",
    "        **angles,\n",
    "        'upper_arm_reba': upper_arm_reba,\n",
    "        'lower_arm_reba': lower_arm_reba,\n",
    "        'neck_reba': neck_reba,\n",
    "        'trunk_reba': trunk_reba,\n",
    "        'leg_reba': leg_reba,\n",
    "        'reba_table_a_score': intermediate_scores['score_a'],\n",
    "        'reba_table_b_score': intermediate_scores['score_b'],\n",
    "        'reba_table_c_score': intermediate_scores['score_c'],\n",
    "        'reba_grand_total': final_score,\n",
    "        'reba_risk_level': risk_level,\n",
    "        'imputed_angles': imputed_angles,\n",
    "        'validated_keypoints': validated_keypoints\n",
    "    }\n",
    "\n",
    "    return result, final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data To CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_fieldnames():\n",
    "    \"\"\"Return the fieldnames for the CSV file with additional REBA table scores\"\"\"\n",
    "    base_fields = [\n",
    "        'File Name', 'Frame', \n",
    "        # Joint Angles\n",
    "        'Neck Angle', 'Left Upper Arm Angle', 'Right Upper Arm Angle',\n",
    "        'Left Lower Arm Angle', 'Right Lower Arm Angle',\n",
    "        'Waist Angle', 'Left Leg Angle', 'Right Leg Angle',\n",
    "        \n",
    "        # REBA Component Scores\n",
    "        'Upper Arm REBA', 'Lower Arm REBA',\n",
    "        'Neck REBA', 'Trunk REBA', 'Leg REBA',\n",
    "        \n",
    "        # New REBA Table Scores\n",
    "        'REBA Table A Score', 'REBA Table B Score', 'REBA Table C Score',\n",
    "        'REBA Grand Total', 'REBA Risk Level',\n",
    "        \n",
    "        # Imputation Flags\n",
    "        'Neck Imputed', 'Left Arm Imputed', 'Right Arm Imputed',\n",
    "        'Left Elbow Imputed', 'Right Elbow Imputed',\n",
    "        'Waist Imputed', 'Left Leg Imputed', 'Right Leg Imputed',\n",
    "    ]\n",
    "    \n",
    "    # Add all keypoint coordinate fields\n",
    "    keypoint_fields = []\n",
    "    for kp_name in KEYPOINT_DICT.keys():\n",
    "        keypoint_fields.append(f'{kp_name} X')\n",
    "        keypoint_fields.append(f'{kp_name} Y')\n",
    "    \n",
    "    return base_fields + keypoint_fields\n",
    "\n",
    "\n",
    "def create_csv_row(angles, filename, frame_num):\n",
    "    \"\"\"Create a dictionary representing one row of CSV data with the new table scores\"\"\"\n",
    "    validated_keypoints = angles.get('validated_keypoints', {})\n",
    "    \n",
    "    # Get the risk level directly from the angles if available, otherwise default to \"Unknown\"\n",
    "    risk_level = angles.get('reba_risk_level', \"Unknown\")\n",
    "    \n",
    "    row = {\n",
    "        'File Name': filename,\n",
    "        'Frame': frame_num,\n",
    "        \n",
    "        # Joint Angles\n",
    "        'Neck Angle': angles.get('neck', -1),\n",
    "        'Left Upper Arm Angle': angles.get('left_upper_arm', -1),\n",
    "        'Right Upper Arm Angle': angles.get('right_upper_arm', -1),\n",
    "        'Left Lower Arm Angle': angles.get('left_lower_arm', -1),\n",
    "        'Right Lower Arm Angle': angles.get('right_lower_arm', -1),\n",
    "        'Waist Angle': angles.get('waist', -1),\n",
    "        'Left Leg Angle': angles.get('left_leg', -1),\n",
    "        'Right Leg Angle': angles.get('right_leg', -1),\n",
    "        \n",
    "        # Individual REBA Scores\n",
    "        'Upper Arm REBA': angles.get('upper_arm_reba', -1),\n",
    "        'Lower Arm REBA': angles.get('lower_arm_reba', -1),\n",
    "        'Neck REBA': angles.get('neck_reba', -1),\n",
    "        'Trunk REBA': angles.get('trunk_reba', -1),\n",
    "        'Leg REBA': angles.get('leg_reba', -1),\n",
    "        \n",
    "        # New REBA Table Scores\n",
    "        'REBA Table A Score': angles.get('reba_table_a_score', -1),\n",
    "        'REBA Table B Score': angles.get('reba_table_b_score', -1),\n",
    "        'REBA Table C Score': angles.get('reba_table_c_score', -1),\n",
    "        'REBA Grand Total': angles.get('reba_grand_total', -1),\n",
    "        'REBA Risk Level': risk_level,\n",
    "        \n",
    "        # Imputation Flags\n",
    "        'Neck Imputed': int(angles.get('imputed_angles', {}).get('neck', False)),\n",
    "        'Left Arm Imputed': int(angles.get('imputed_angles', {}).get('left_upper_arm', False)),\n",
    "        'Right Arm Imputed': int(angles.get('imputed_angles', {}).get('right_upper_arm', False)),\n",
    "        'Left Elbow Imputed': int(angles.get('imputed_angles', {}).get('left_lower_arm', False)),\n",
    "        'Right Elbow Imputed': int(angles.get('imputed_angles', {}).get('right_lower_arm', False)),\n",
    "        'Waist Imputed': int(angles.get('imputed_angles', {}).get('waist', False)),\n",
    "        'Left Leg Imputed': int(angles.get('imputed_angles', {}).get('left_leg', False)),\n",
    "        'Right Leg Imputed': int(angles.get('imputed_angles', {}).get('right_leg', False)),\n",
    "    }\n",
    "    \n",
    "    # Add keypoint coordinates with None for invalid points\n",
    "    for kp_name in KEYPOINT_DICT.keys():\n",
    "        kp = validated_keypoints.get(kp_name, {'x': None, 'y': None})\n",
    "        row[f'{kp_name} X'] = kp.get('x', None)\n",
    "        row[f'{kp_name} Y'] = kp.get('y', None)\n",
    "    \n",
    "    return row\n",
    "\n",
    "\n",
    "def save_angles_to_csv(angles_list, output_csv, filename=None, frame_num=0, is_new_file=False):\n",
    "    \"\"\"Save all joint angles, REBA scores, and keypoints to CSV\"\"\"\n",
    "    import os\n",
    "    import csv\n",
    "    \n",
    "    file_exists = os.path.exists(output_csv) and os.path.getsize(output_csv) > 0\n",
    "    \n",
    "    with open(output_csv, 'a' if not is_new_file and file_exists else 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=get_csv_fieldnames())\n",
    "        \n",
    "        # Write header if it's a new file or if the file is empty\n",
    "        if is_new_file or not file_exists:\n",
    "            writer.writeheader()\n",
    "\n",
    "        for idx, angles in enumerate(angles_list):\n",
    "            row_filename = filename if filename else angles.get('filename', 'unknown')\n",
    "            row = create_csv_row(angles, row_filename, frame_num + idx)\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_media(input_path, output_folder, output_csv, frame_interval=3, batch_size=32, checkpoint_file='checkpoint.txt'):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Check if we need to create a new CSV file\n",
    "    is_new_csv = not os.path.exists(output_csv) or os.path.getsize(output_csv) == 0\n",
    "\n",
    "    # Initialize data collection\n",
    "    all_angles = []\n",
    "    all_filenames = []\n",
    "\n",
    "    # Directory Processing Mode\n",
    "    if os.path.isdir(input_path):\n",
    "        print(f\"\\nðŸ“‚ Processing directory: {input_path}\")\n",
    "        files = sorted([f for f in os.listdir(input_path) if f.lower().endswith(\n",
    "            ('.png','.jpg','.jpeg','.bmp','.tiff','.gif','.mp4','.avi','.mov','.mkv')\n",
    "        )])\n",
    "\n",
    "        total_files = len(files)\n",
    "        for i, fname in enumerate(files, 1):\n",
    "            full_path = os.path.join(input_path, fname)\n",
    "            print(f\"\\n[{i}/{total_files}] Processing: {fname}\")\n",
    "\n",
    "            # Use frame_interval=1 for images, keep specified interval for videos\n",
    "            current_interval = 1 if fname.lower().endswith(('.png','.jpg','.jpeg','.bmp','.tiff','.gif')) else frame_interval\n",
    "\n",
    "            # Process each file\n",
    "            angles = process_single_media(\n",
    "                full_path, \n",
    "                output_folder,\n",
    "                output_csv,\n",
    "                current_interval,\n",
    "                batch_size,\n",
    "                checkpoint_file,\n",
    "                save_to_csv=False\n",
    "            )\n",
    "\n",
    "            if angles is not None:\n",
    "                all_angles.append(angles)\n",
    "                all_filenames.append(fname)\n",
    "\n",
    "        # Save all collected data to CSV at once\n",
    "        if all_angles:\n",
    "            save_angles_to_csv(all_angles, output_csv, is_new_file=is_new_csv)\n",
    "            print(f\"\\nâœ“ Saved data for {len(all_angles)} files to {output_csv}\")\n",
    "        return\n",
    "\n",
    "    # Single File Processing\n",
    "    process_single_media(\n",
    "        input_path,\n",
    "        output_folder,\n",
    "        output_csv,\n",
    "        frame_interval,\n",
    "        batch_size,\n",
    "        checkpoint_file,\n",
    "        save_to_csv=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_media(input_path, output_folder, output_csv, frame_interval, batch_size=32, checkpoint_file='checkpoint.txt', save_to_csv=False):\n",
    "    \"\"\"\n",
    "    Process a single image or video file for pose estimation.\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to the input media file (image or video)\n",
    "        output_folder: Folder to save the visualization results\n",
    "        output_csv: Path to save CSV data\n",
    "        frame_interval: Process every nth frame for videos\n",
    "        batch_size: Number of frames to process in a batch\n",
    "        checkpoint_file: File to store processing checkpoint for resuming\n",
    "        save_to_csv: Whether to save single image results to CSV\n",
    "    \n",
    "    Returns:\n",
    "        For single images: dict with angle data, None for videos\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(input_path)\n",
    "    print(f\"\\nStarting processing for: {filename}\")\n",
    "    \n",
    "    # ====== 1. Check for resume conditions ======\n",
    "    is_new_csv, resume_frame, existing_frames = check_resume_conditions(\n",
    "        filename, output_csv, checkpoint_file)\n",
    "    \n",
    "    # ====== 2. Process based on file type ======\n",
    "    file_extension = os.path.splitext(input_path)[1].lower()\n",
    "    \n",
    "    # Process image file\n",
    "    if file_extension in ('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.gif'):\n",
    "        return process_single_image(\n",
    "            input_path, filename, output_folder, output_csv, \n",
    "            is_new_csv, save_to_csv)\n",
    "    \n",
    "    # Process video file\n",
    "    elif file_extension in ('.mp4', '.avi', '.mov', '.mkv'):\n",
    "        return process_video(\n",
    "            input_path, filename, output_folder, output_csv, \n",
    "            frame_interval, batch_size, checkpoint_file,\n",
    "            is_new_csv, resume_frame, existing_frames, apply_rotation)\n",
    "    \n",
    "    # Unsupported file type\n",
    "    else:\n",
    "        print(\"âš  Unsupported file type\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def check_resume_conditions(filename, output_csv, checkpoint_file):\n",
    "    \"\"\"Check if we need to resume processing and from where.\"\"\"\n",
    "    is_new_csv = not os.path.exists(output_csv)\n",
    "    resume_frame = 0\n",
    "    existing_frames = set()\n",
    "    \n",
    "    # Check checkpoint file first\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        try:\n",
    "            with open(checkpoint_file, 'r') as f:\n",
    "                content = f.read().strip()\n",
    "                if content:\n",
    "                    last_file, last_frame = content.split(',')\n",
    "                    if last_file == filename:\n",
    "                        resume_frame = int(last_frame)\n",
    "                        print(f\"â†» Resuming {filename} from frame {resume_frame} (checkpoint)\")\n",
    "        except Exception as e:\n",
    "            print(\"âš  Checkpoint file error:\", e)\n",
    "\n",
    "    # Check CSV for existing frames\n",
    "    if os.path.exists(output_csv):\n",
    "        try:\n",
    "            df_existing = pd.read_csv(output_csv)\n",
    "            if not df_existing.empty and 'File Name' in df_existing.columns:\n",
    "                file_records = df_existing[df_existing['File Name'] == filename]\n",
    "                if not file_records.empty:\n",
    "                    existing_frames = set(file_records['Frame'].values)\n",
    "                    print(f\"â„¹ Found {len(existing_frames)} existing frames in CSV\")\n",
    "                    \n",
    "                    # If no checkpoint but CSV has data, resume from last CSV frame + 1\n",
    "                    if resume_frame == 0 and len(existing_frames) > 0:\n",
    "                        resume_frame = max(existing_frames) + 1\n",
    "                        print(f\"â†» Resuming {filename} from frame {resume_frame} (CSV)\")\n",
    "        except Exception as e:\n",
    "            print(\"âš  CSV read error:\", e)\n",
    "            \n",
    "    return is_new_csv, resume_frame, existing_frames\n",
    "\n",
    "\n",
    "def process_single_image(input_path, filename, output_folder, output_csv, is_new_csv, save_to_csv):\n",
    "    \"\"\"Process a single image file.\"\"\"\n",
    "    try:\n",
    "        # Read and convert image\n",
    "        frame = cv2.imread(input_path)\n",
    "        if frame is None:\n",
    "            print(f\"âš  Error: Could not read image {filename}\")\n",
    "            return None\n",
    "            \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # First run inference to detect keypoints\n",
    "        keypoints, processed_img, original_img, _ = run_inference(\n",
    "            movenet, frame, init_crop_region(frame.shape[0], frame.shape[1]), \n",
    "            crop_size=[input_size, input_size])\n",
    "        \n",
    "        # Add flipping check for single images\n",
    "        flip_required = should_flip_image(keypoints)\n",
    "        print(f\"  Orientation: {'FLIPPED' if flip_required else 'NORMAL'}\")\n",
    "        \n",
    "        # If flipping is required, flip the image and run inference again\n",
    "        if flip_required:\n",
    "            flipped_frame = cv2.flip(frame, 1)\n",
    "            keypoints, processed_img, original_img, _ = run_inference(\n",
    "                movenet, flipped_frame, init_crop_region(flipped_frame.shape[0], flipped_frame.shape[1]), \n",
    "                crop_size=[input_size, input_size])\n",
    "        \n",
    "        # Create and save visualization\n",
    "        vis_frame = draw_prediction_on_image(processed_img, keypoints, original_img, flip_required)\n",
    "        vis_frame = cv2.cvtColor(vis_frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        output_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}_pose.png\")\n",
    "        cv2.imwrite(output_path, vis_frame)\n",
    "        print(f\"Saved visualization to {output_path}\")\n",
    "\n",
    "        # Calculate angles and joint positions\n",
    "        angles, _ = get_joint_angles_and_labels(keypoints)\n",
    "        \n",
    "        if angles is None:\n",
    "            print(f\"âš  Skipping image {filename} - insufficient keypoints\")\n",
    "            return None\n",
    "            \n",
    "        # Add filename to angles dict for CSV saving\n",
    "        angles['filename'] = filename\n",
    "        \n",
    "        if save_to_csv:\n",
    "            save_angles_to_csv([angles], output_csv, \n",
    "                            filename=filename, frame_num=0, is_new_file=is_new_csv)\n",
    "        \n",
    "        return angles\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš  Error processing image {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_video(input_path, filename, output_folder, output_csv, \n",
    "                 frame_interval, batch_size, checkpoint_file,\n",
    "                 is_new_csv, resume_frame, existing_frames, apply_rotation):\n",
    "    \"\"\"Process a video file.\"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"âš  Error opening video {filename}\")\n",
    "        return None\n",
    "        \n",
    "    # Get video rotation metadata\n",
    "    rotation = get_video_rotation(input_path)\n",
    "    print(f\"Rotation detected: {rotation}Â°\")\n",
    "    \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    duration = total_frames / fps if fps > 0 else 0\n",
    "    \n",
    "    print(f\"  Total frames: {total_frames} (~{duration:.1f} seconds)\")\n",
    "    print(f\"  Processing every {frame_interval} frames\")\n",
    "    \n",
    "    # Process first frame to determine orientation\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(f\"âš  Error reading first frame of {filename}\")\n",
    "        cap.release()\n",
    "        return None\n",
    "        \n",
    "    # Apply rotation to first frame\n",
    "    first_frame = apply_rotation(first_frame, rotation)\n",
    "    first_frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Determine if flipping is needed\n",
    "    kpts, proc_img, orig_img, flip_required = run_inference(\n",
    "        movenet, first_frame_rgb, \n",
    "        init_crop_region(first_frame_rgb.shape[0], first_frame_rgb.shape[1]),\n",
    "        crop_size=[input_size, input_size])\n",
    "        \n",
    "    print(f\"  Orientation: {'FLIPPED' if flip_required else 'NORMAL'}\")\n",
    "\n",
    "    # Save first frame visualization\n",
    "    vis_frame = draw_prediction_on_image(proc_img, kpts, orig_img, flip_required)\n",
    "    vis_frame = cv2.cvtColor(vis_frame, cv2.COLOR_RGB2BGR)\n",
    "    save_visualized_frame(vis_frame, output_folder, 0, flip_required)\n",
    "\n",
    "    # Process all frames\n",
    "    with open(output_csv, 'a' if not is_new_csv else 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=get_csv_fieldnames())\n",
    "        if is_new_csv:\n",
    "            writer.writeheader()\n",
    "\n",
    "        # Resume from previous position if needed\n",
    "        if resume_frame > 0:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, resume_frame)\n",
    "            print(f\"  Seeking to frame {resume_frame}/{total_frames}\")\n",
    "            \n",
    "        frame_count = resume_frame if resume_frame > 0 else 0\n",
    "        processed_count = 0\n",
    "        \n",
    "        # Main processing loop\n",
    "        while cap.isOpened():\n",
    "            # Read batch of frames\n",
    "            frames = []\n",
    "            for _ in range(batch_size):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frames.append(frame)\n",
    "\n",
    "            if not frames:\n",
    "                break\n",
    "\n",
    "            # Process each frame in batch\n",
    "            for i, frame in enumerate(frames):\n",
    "                current_frame = frame_count + i\n",
    "                if current_frame % frame_interval == 0 and current_frame not in existing_frames:\n",
    "                    try:\n",
    "                        # Apply rotation\n",
    "                        frame = apply_rotation(frame, rotation)\n",
    "                        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                        \n",
    "                        # Apply flipping if needed (consistent with first frame)\n",
    "                        if flip_required:\n",
    "                            frame_rgb = cv2.flip(frame_rgb, 1)\n",
    "                        \n",
    "                        # Run inference\n",
    "                        kpts, proc_img, orig_img, _ = run_inference(\n",
    "                            movenet, frame_rgb,\n",
    "                            init_crop_region(frame_rgb.shape[0], frame_rgb.shape[1]),\n",
    "                            crop_size=[input_size, input_size])\n",
    "\n",
    "                        # Calculate angles\n",
    "                        angles, _ = get_joint_angles_and_labels(kpts)\n",
    "                        if angles is None:\n",
    "                            print(f\"âš  Skipping frame {current_frame} - insufficient keypoints\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Add to CSV\n",
    "                        processed_count += 1\n",
    "                        row = create_csv_row(angles, filename, current_frame)\n",
    "                        writer.writerow(row)\n",
    "\n",
    "                        # Periodically save visualizations\n",
    "                        if current_frame % 1000 == 0:\n",
    "                            vis_frame = draw_prediction_on_image(\n",
    "                                proc_img, kpts, orig_img, flip_required)\n",
    "                            vis_frame = cv2.cvtColor(vis_frame, cv2.COLOR_RGB2BGR)\n",
    "                            save_visualized_frame(vis_frame, output_folder, current_frame, flip_required)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"âš  Frame {current_frame} error: {str(e)[:100]}\")\n",
    "\n",
    "            # Update progress\n",
    "            frame_count += len(frames)\n",
    "            progress = (frame_count / total_frames) * 100\n",
    "            print(f\"  Progress: {frame_count}/{total_frames} ({progress:.1f}%) - Processed: {processed_count}\", end='\\r')\n",
    "            \n",
    "            # Update checkpoint\n",
    "            with open(checkpoint_file, 'w') as f:\n",
    "                f.write(f\"{filename},{frame_count}\\n\")\n",
    "\n",
    "        # Cleanup\n",
    "        cap.release()\n",
    "        print(f\"\\nâœ“ Completed {filename} - Processed {processed_count} keyframes\")\n",
    "        try:\n",
    "            if os.path.exists(checkpoint_file):\n",
    "                os.remove(checkpoint_file)\n",
    "        except Exception as e:\n",
    "            print(f\"âš  Failed to remove checkpoint: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with your parameters\n",
    "process_media('Video', 'rev', 'Datarevisi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
